{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dcgan.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"VTJlUWwFwXSw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"b7443d72-8e18-461c-82de-1f01a25b34e6","executionInfo":{"status":"ok","timestamp":1547413833005,"user_tz":480,"elapsed":2558,"user":{"displayName":"Hao Chuan Lei","photoUrl":"","userId":"04091475403023878525"}}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd \"/content/drive/My Drive/Local/dcgan\"\n","\n","import tensorflow as tf\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/My Drive/Local/dcgan\n","Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"metadata":{"id":"dPLdcsJAw0c4","colab_type":"text"},"cell_type":"markdown","source":["Comment out the above if not using Google Colaboratory. "]},{"metadata":{"id":"gCM0JGlwTCPZ","colab_type":"text"},"cell_type":"markdown","source":["## Define the Network\n","Below is the code used to create the DCGAN. Note that much of this code is taken from https://github.com/eriklindernoren/Keras-GAN. The main modifications here are some simplifications to variable names, added functionality for saving images, and the ability to plot the progression of the GAN over time on the same noise batch. "]},{"metadata":{"id":"Z-9jcAMZxKP8","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.datasets import mnist\n","from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n","from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n","from keras.layers.advanced_activations import LeakyReLU\n","from keras.layers.convolutional import UpSampling2D, Conv2D\n","from keras.models import Sequential, Model\n","from keras.optimizers import Adam\n","import matplotlib.pyplot as plt\n","import sys\n","import numpy as np\n","import os\n","import imageio"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1WncYsEfxNkF","colab_type":"code","colab":{}},"cell_type":"code","source":["class DCGAN(): \n","  def __init__(self, name= \"mnist\", imgrows=28, imgcols=28, channels= 1, latent_dim= 100):\n","    self.name= name\n","    self.img_rows= imgrows\n","    self.img_cols= imgcols\n","    self.channels= channels\n","    self.img_shape= (self.img_rows, self.img_cols, self.channels)\n","    self.latent_dim= latent_dim\n","    \n","    #parameters chosen from the paper by Radford et al.\n","    optimizer= Adam(0.0002, 0.5)\n","    \n","    #construct generator\n","    self.generator= self.generator()\n","    \n","    #construct discriminator\n","    self.discriminator= self.discriminator()\n","    self.discriminator.compile(loss= \"binary_crossentropy\",\n","                              optimizer= optimizer, \n","                              metrics= ['accuracy'])\n","    \n","    #generator generates images from noise\n","    noise= Input(shape= (self.latent_dim, ))\n","    img= self.generator(noise)\n","    \n","    #only train generator\n","    self.discriminator.trainable= False\n","    \n","    #validity of image as determined by discriminator\n","    val= self.discriminator(img)\n","    \n","    #stack generator and discriminator\n","    self.GAN = Model(noise, val)\n","    self.GAN.compile(loss= \"binary_crossentropy\", optimizer= optimizer)\n","    \n","  \n","  def generator(self): \n","    model = Sequential()\n","    model.add(Dense(128 * 7 * 7, activation= \"relu\", input_dim= self.latent_dim))\n","    model.add(Reshape((7, 7, 128)))\n","    model.add(UpSampling2D())\n","    model.add(Conv2D(128, kernel_size= 3, padding= \"same\"))\n","    model.add(BatchNormalization(momentum= 0.8))\n","    model.add(Activation(\"relu\"))\n","    model.add(UpSampling2D())\n","    model.add(Conv2D(64, kernel_size= 3, padding= \"same\"))\n","    model.add(BatchNormalization(momentum= 0.8))\n","    model.add(Activation(\"relu\"))\n","    model.add(Conv2D(self.channels, kernel_size= 3, padding= \"same\"))\n","    model.add(Activation(\"tanh\"))\n","    print(\"Generator Summary ... \")\n","    model.summary()\n","    \n","    #input noise into generator\n","    noise= Input(shape= (self.latent_dim, ))\n","    #pass noise through model to retrieve image\n","    img= model(noise)\n","    \n","    return Model(noise, img)\n","  \n","  def discriminator(self): \n","    model= Sequential()\n","    model.add(Conv2D(32, kernel_size= 3, strides= 2, input_shape= self.img_shape, padding= \"same\"))\n","    model.add(LeakyReLU(alpha= 0.2))\n","    model.add(Dropout(0.25))\n","    model.add(Conv2D(64, kernel_size= 3, strides= 2, padding= \"same\"))\n","    model.add(ZeroPadding2D(padding= ((0, 1), (0, 1))))\n","    model.add(BatchNormalization(momentum= 0.8))\n","    model.add(LeakyReLU(alpha= 0.2))\n","    model.add(Dropout(0.25))\n","    model.add(Conv2D(128, kernel_size= 3, strides= 2, padding= \"same\"))\n","    model.add(BatchNormalization(momentum= 0.8))\n","    model.add(LeakyReLU(alpha= 0.2))\n","    model.add(Dropout(0.25))\n","    model.add(Conv2D(256, kernel_size=3, strides= 1, padding= \"same\"))\n","    model.add(BatchNormalization(momentum= 0.8))\n","    model.add(LeakyReLU(alpha= 0.2))\n","    model.add(Dropout(0.25))\n","    model.add(Flatten())\n","    model.add(Dense(1, activation= \"sigmoid\"))\n","    print(\"Discriminator Summary ... \")\n","    model.summary()\n","    \n","    img= Input(shape= self.img_shape)\n","    val= model(img)\n","    return Model(img, val)\n","  \n","  def images(self, noise, rows= 5, cols= 5, name= \"untitled\", title= \"\",\n","             show= False): \n","    generated= self.generator.predict(noise)\n","    \n","    #rescale images to [0, 1]\n","    generated= 0.5* generated + 0.5\n","    \n","    fig, ax= plt.subplots(rows, cols)\n","    count= 0\n","    for row in range(rows): \n","      for col in range(cols): \n","        ax[row, col].imshow(generated[count, :, :, 0], cmap= \"gray\")\n","        ax[row, col].axis(\"off\")\n","        count += 1\n","    \n","    fig.suptitle(title)    \n","    fig.savefig(\"%s.png\" % name)\n","    \n","    # Used to return the plot as an image rray\n","    fig.canvas.draw()       # draw the canvas, cache the renderer\n","    image = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n","    image = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n","    \n","    if not show: \n","      plt.close()\n","    \n","    return image\n","    \n","      \n","  def train(self, images, epochs= 4000, batch_size= 32, \n","           interval= 50, rows= 5, cols= 5):\n","    #purely for saving purposes ...\n","    fixed_noise_batch= np.random.normal(0, 1, (rows * cols, self.latent_dim))\n","    plots= []\n","    \n","    #if the directory specified by name doesn't exist, create it\n","    if not os.path.exists(self.name):\n","       os.makedirs(self.name)\n","    \n","    images= images / 127.5 - 1\n","    images= np.expand_dims(images, axis= 3)\n","\n","    #adversarial ground truths\n","    valid = np.ones((batch_size, 1))\n","    fake = np.zeros((batch_size, 1))\n","\n","    for epoch in range(epochs + 1):\n","      #train discriminator....\n","      #select random images\n","      imgs= images[np.random.randint(0, images.shape[0], batch_size)]\n","\n","      #create random noise and generate new images\n","      noise= np.random.normal(0, 1, (batch_size, self.latent_dim))\n","      generated= self.generator.predict(noise)\n","\n","      d_loss_real= self.discriminator.train_on_batch(imgs, valid)\n","      d_loss_fake= self.discriminator.train_on_batch(generated, fake)\n","      d_loss= 0.5* np.add(d_loss_real, d_loss_fake)\n","      \n","      #train generator, by creating images that seem like valid ones\n","      g_loss= self.GAN.train_on_batch(noise, valid)\n","      \n","      if epoch % interval == 0:\n","        status= \"[%d] D loss: %f, acc: %.2f%% || G loss: %f\" %(epoch, \n","                 d_loss[0], d_loss[1] * 100, g_loss)\n","        print(status)\n","        \n","        #generate images\n","        name= \"%s/%d\" % (self.name, epoch)\n","        plot= self.images(name= name, noise= fixed_noise_batch, \n","                          title= status, rows= rows, cols= cols)\n","        plots.append(plot)\n","    \n","    #save a gif of the progression for visualization\n","    imageio.mimsave(\"%s/progression.gif\" % self.name, np.array(plots), fps=8)\n","    "],"execution_count":0,"outputs":[]},{"metadata":{"id":"5hCX0HLvS6mP","colab_type":"text"},"cell_type":"markdown","source":["## Run the Code\n","Below is the code to run the dcgan on the mnist dataset. "]},{"metadata":{"id":"arwTiZxTxYyN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1309},"outputId":"d65af269-2b8d-455e-e0c7-48e7dd6a363c","executionInfo":{"status":"ok","timestamp":1547417108304,"user_tz":480,"elapsed":3109,"user":{"displayName":"Hao Chuan Lei","photoUrl":"","userId":"04091475403023878525"}}},"cell_type":"code","source":["(X_train, _), (_, _) = mnist.load_data()\n","dcgan= DCGAN()"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Generator Summary ... \n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_17 (Dense)             (None, 6272)              633472    \n","_________________________________________________________________\n","reshape_9 (Reshape)          (None, 7, 7, 128)         0         \n","_________________________________________________________________\n","up_sampling2d_17 (UpSampling (None, 14, 14, 128)       0         \n","_________________________________________________________________\n","conv2d_57 (Conv2D)           (None, 14, 14, 128)       147584    \n","_________________________________________________________________\n","batch_normalization_41 (Batc (None, 14, 14, 128)       512       \n","_________________________________________________________________\n","activation_25 (Activation)   (None, 14, 14, 128)       0         \n","_________________________________________________________________\n","up_sampling2d_18 (UpSampling (None, 28, 28, 128)       0         \n","_________________________________________________________________\n","conv2d_58 (Conv2D)           (None, 28, 28, 64)        73792     \n","_________________________________________________________________\n","batch_normalization_42 (Batc (None, 28, 28, 64)        256       \n","_________________________________________________________________\n","activation_26 (Activation)   (None, 28, 28, 64)        0         \n","_________________________________________________________________\n","conv2d_59 (Conv2D)           (None, 28, 28, 1)         577       \n","_________________________________________________________________\n","activation_27 (Activation)   (None, 28, 28, 1)         0         \n","=================================================================\n","Total params: 856,193\n","Trainable params: 855,809\n","Non-trainable params: 384\n","_________________________________________________________________\n","Discriminator Summary ... \n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_60 (Conv2D)           (None, 14, 14, 32)        320       \n","_________________________________________________________________\n","leaky_re_lu_33 (LeakyReLU)   (None, 14, 14, 32)        0         \n","_________________________________________________________________\n","dropout_33 (Dropout)         (None, 14, 14, 32)        0         \n","_________________________________________________________________\n","conv2d_61 (Conv2D)           (None, 7, 7, 64)          18496     \n","_________________________________________________________________\n","zero_padding2d_9 (ZeroPaddin (None, 8, 8, 64)          0         \n","_________________________________________________________________\n","batch_normalization_43 (Batc (None, 8, 8, 64)          256       \n","_________________________________________________________________\n","leaky_re_lu_34 (LeakyReLU)   (None, 8, 8, 64)          0         \n","_________________________________________________________________\n","dropout_34 (Dropout)         (None, 8, 8, 64)          0         \n","_________________________________________________________________\n","conv2d_62 (Conv2D)           (None, 4, 4, 128)         73856     \n","_________________________________________________________________\n","batch_normalization_44 (Batc (None, 4, 4, 128)         512       \n","_________________________________________________________________\n","leaky_re_lu_35 (LeakyReLU)   (None, 4, 4, 128)         0         \n","_________________________________________________________________\n","dropout_35 (Dropout)         (None, 4, 4, 128)         0         \n","_________________________________________________________________\n","conv2d_63 (Conv2D)           (None, 4, 4, 256)         295168    \n","_________________________________________________________________\n","batch_normalization_45 (Batc (None, 4, 4, 256)         1024      \n","_________________________________________________________________\n","leaky_re_lu_36 (LeakyReLU)   (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","dropout_36 (Dropout)         (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","flatten_9 (Flatten)          (None, 4096)              0         \n","_________________________________________________________________\n","dense_18 (Dense)             (None, 1)                 4097      \n","=================================================================\n","Total params: 393,729\n","Trainable params: 392,833\n","Non-trainable params: 896\n","_________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"-GfCaBgm9UUf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1431},"outputId":"550c8152-db03-475e-aad3-b0e3f10b8f6b","executionInfo":{"status":"ok","timestamp":1547417501088,"user_tz":480,"elapsed":390107,"user":{"displayName":"Hao Chuan Lei","photoUrl":"","userId":"04091475403023878525"}}},"cell_type":"code","source":["dcgan.train(images= X_train)"],"execution_count":34,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n","  'Discrepancy between trainable weights and collected trainable'\n"],"name":"stderr"},{"output_type":"stream","text":["[0] D loss: 1.011732, acc: 37.50% || G loss: 1.025782\n","[50] D loss: 0.748307, acc: 59.38% || G loss: 1.516396\n","[100] D loss: 0.810506, acc: 53.12% || G loss: 1.171163\n","[150] D loss: 0.795745, acc: 46.88% || G loss: 1.048355\n","[200] D loss: 0.758722, acc: 50.00% || G loss: 1.077071\n","[250] D loss: 0.883077, acc: 45.31% || G loss: 0.921695\n","[300] D loss: 0.840653, acc: 39.06% || G loss: 0.940531\n","[350] D loss: 0.750360, acc: 46.88% || G loss: 1.097787\n","[400] D loss: 0.806442, acc: 46.88% || G loss: 0.993107\n","[450] D loss: 0.725249, acc: 56.25% || G loss: 1.148484\n","[500] D loss: 0.739208, acc: 54.69% || G loss: 1.050460\n","[550] D loss: 0.812821, acc: 40.62% || G loss: 1.027155\n","[600] D loss: 0.627605, acc: 67.19% || G loss: 1.149585\n","[650] D loss: 0.689739, acc: 62.50% || G loss: 1.250378\n","[700] D loss: 0.628848, acc: 65.62% || G loss: 0.909651\n","[750] D loss: 0.640235, acc: 62.50% || G loss: 1.052664\n","[800] D loss: 0.634640, acc: 68.75% || G loss: 1.083387\n","[850] D loss: 0.669509, acc: 67.19% || G loss: 1.193631\n","[900] D loss: 0.665350, acc: 59.38% || G loss: 0.955692\n","[950] D loss: 0.738550, acc: 51.56% || G loss: 1.071017\n","[1000] D loss: 0.720440, acc: 53.12% || G loss: 1.140358\n","[1050] D loss: 0.685927, acc: 59.38% || G loss: 1.046442\n","[1100] D loss: 0.631171, acc: 71.88% || G loss: 0.970512\n","[1150] D loss: 0.749568, acc: 51.56% || G loss: 0.972329\n","[1200] D loss: 0.661226, acc: 67.19% || G loss: 1.133818\n","[1250] D loss: 0.611319, acc: 59.38% || G loss: 0.890995\n","[1300] D loss: 0.694557, acc: 54.69% || G loss: 1.078663\n","[1350] D loss: 0.690100, acc: 56.25% || G loss: 0.917181\n","[1400] D loss: 0.691156, acc: 62.50% || G loss: 0.789032\n","[1450] D loss: 0.679626, acc: 54.69% || G loss: 0.823397\n","[1500] D loss: 0.758665, acc: 48.44% || G loss: 0.929197\n","[1550] D loss: 0.691733, acc: 54.69% || G loss: 0.988300\n","[1600] D loss: 0.655853, acc: 62.50% || G loss: 0.972204\n","[1650] D loss: 0.814859, acc: 45.31% || G loss: 0.958325\n","[1700] D loss: 0.773696, acc: 45.31% || G loss: 1.026803\n","[1750] D loss: 0.703092, acc: 54.69% || G loss: 1.002727\n","[1800] D loss: 0.561437, acc: 79.69% || G loss: 1.080911\n","[1850] D loss: 0.593211, acc: 71.88% || G loss: 1.082283\n","[1900] D loss: 0.620287, acc: 64.06% || G loss: 1.115049\n","[1950] D loss: 0.663462, acc: 59.38% || G loss: 1.076459\n","[2000] D loss: 0.654410, acc: 64.06% || G loss: 1.003015\n","[2050] D loss: 0.721445, acc: 53.12% || G loss: 0.943657\n","[2100] D loss: 0.644475, acc: 60.94% || G loss: 0.931798\n","[2150] D loss: 0.627984, acc: 75.00% || G loss: 0.974935\n","[2200] D loss: 0.630270, acc: 60.94% || G loss: 1.203390\n","[2250] D loss: 0.714797, acc: 45.31% || G loss: 0.916833\n","[2300] D loss: 0.749527, acc: 46.88% || G loss: 1.036930\n","[2350] D loss: 0.646374, acc: 62.50% || G loss: 1.012890\n","[2400] D loss: 0.566698, acc: 78.12% || G loss: 0.853507\n","[2450] D loss: 0.720188, acc: 53.12% || G loss: 0.889787\n","[2500] D loss: 0.692642, acc: 57.81% || G loss: 0.901708\n","[2550] D loss: 0.563154, acc: 71.88% || G loss: 1.079001\n","[2600] D loss: 0.634710, acc: 57.81% || G loss: 0.934064\n","[2650] D loss: 0.659122, acc: 53.12% || G loss: 0.952043\n","[2700] D loss: 0.637498, acc: 60.94% || G loss: 1.018826\n","[2750] D loss: 0.631070, acc: 68.75% || G loss: 0.955914\n","[2800] D loss: 0.676648, acc: 60.94% || G loss: 1.033195\n","[2850] D loss: 0.658458, acc: 53.12% || G loss: 1.067357\n","[2900] D loss: 0.738862, acc: 51.56% || G loss: 0.975787\n","[2950] D loss: 0.609576, acc: 65.62% || G loss: 0.874120\n","[3000] D loss: 0.627173, acc: 62.50% || G loss: 1.066485\n","[3050] D loss: 0.684258, acc: 59.38% || G loss: 0.869246\n","[3100] D loss: 0.629524, acc: 67.19% || G loss: 1.032264\n","[3150] D loss: 0.625875, acc: 65.62% || G loss: 1.010107\n","[3200] D loss: 0.655214, acc: 60.94% || G loss: 0.951085\n","[3250] D loss: 0.616186, acc: 67.19% || G loss: 1.071121\n","[3300] D loss: 0.646743, acc: 62.50% || G loss: 0.961857\n","[3350] D loss: 0.704136, acc: 54.69% || G loss: 1.074007\n","[3400] D loss: 0.617847, acc: 62.50% || G loss: 1.082428\n","[3450] D loss: 0.551443, acc: 71.88% || G loss: 1.029643\n","[3500] D loss: 0.721533, acc: 54.69% || G loss: 1.007698\n","[3550] D loss: 0.535848, acc: 76.56% || G loss: 1.217085\n","[3600] D loss: 0.690744, acc: 56.25% || G loss: 0.911309\n","[3650] D loss: 0.613213, acc: 60.94% || G loss: 1.060666\n","[3700] D loss: 0.588347, acc: 67.19% || G loss: 1.030883\n","[3750] D loss: 0.575772, acc: 71.88% || G loss: 1.092251\n","[3800] D loss: 0.694663, acc: 59.38% || G loss: 0.997245\n","[3850] D loss: 0.572637, acc: 64.06% || G loss: 0.892268\n","[3900] D loss: 0.659431, acc: 60.94% || G loss: 0.964461\n","[3950] D loss: 0.693516, acc: 54.69% || G loss: 0.837783\n"],"name":"stdout"}]}]}