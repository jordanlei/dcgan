{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dcgan-cifar.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"VTJlUWwFwXSw","colab_type":"code","outputId":"d75d8332-00e1-42ac-9960-caf7fab3526f","executionInfo":{"status":"ok","timestamp":1547428163076,"user_tz":480,"elapsed":3887,"user":{"displayName":"Hao Chuan Lei","photoUrl":"","userId":"04091475403023878525"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd \"/content/drive/My Drive/Local/dcgan\"\n","\n","import tensorflow as tf\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/My Drive/Local/dcgan\n","Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"metadata":{"id":"dPLdcsJAw0c4","colab_type":"text"},"cell_type":"markdown","source":["Comment out the above if not using Google Colaboratory. "]},{"metadata":{"id":"gCM0JGlwTCPZ","colab_type":"text"},"cell_type":"markdown","source":["## Define the Network\n","Below is the code used to create the DCGAN. Note that much of this code is taken from https://github.com/eriklindernoren/Keras-GAN. The main modifications here are some simplifications to variable names, added functionality for saving images, and the ability to plot the progression of the GAN over time on the same noise batch. "]},{"metadata":{"id":"Z-9jcAMZxKP8","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.datasets import mnist, cifar10\n","from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n","from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n","from keras.layers.advanced_activations import LeakyReLU\n","from keras.layers.convolutional import UpSampling2D, Conv2D, Conv2DTranspose\n","from keras.models import Sequential, Model\n","from keras.optimizers import Adam\n","import matplotlib.pyplot as plt\n","from keras.preprocessing import image as Image\n","import sys\n","import numpy as np\n","import os\n","import imageio"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1WncYsEfxNkF","colab_type":"code","outputId":"e0a7905d-61c3-4213-a0bd-0450529a6d6a","executionInfo":{"status":"ok","timestamp":1547429993919,"user_tz":480,"elapsed":299247,"user":{"displayName":"Hao Chuan Lei","photoUrl":"","userId":"04091475403023878525"}},"colab":{"base_uri":"https://localhost:8080/","height":1737}},"cell_type":"code","source":["latent_dim = 32\n","channels =3\n","height =32\n","width = 32\n","\n","##generator network\n","generator_input = Input(shape=(latent_dim, ))\n","\n","x = Dense(128 * 16 * 16)(generator_input)\n","x = LeakyReLU()(x)\n","x = Reshape((16,16,128))(x)\n","\n","x = Conv2D(256, 5, padding='same')(x)  # 16*16*256\n","x = BatchNormalization(momentum=0.8)(x)\n","x = LeakyReLU()(x)\n","x = UpSampling2D()(x)\n","#x = Conv2DTranspose(256, 4, strides=2, padding='same')(x) # 32*32*256 upsampling\n","x = LeakyReLU()(x)\n","x = Conv2D(256, 5, padding='same')(x)\n","x = BatchNormalization(momentum=0.8)(x)\n","x = LeakyReLU()(x)\n","x = Conv2D(256, 5, padding='same')(x)\n","x = BatchNormalization(momentum=0.8)(x)\n","x = LeakyReLU()(x)\n","x = Conv2D(channels, 7, activation='tanh', padding='same')(x) #sample 32*32*3 image\n","\n","generator = Model(generator_input, x)\n","generator.summary()\n","\n","#descriminator network\n","descriminator_input = Input(shape=(height, width, channels))\n","x = Conv2D(128, 3)(descriminator_input)\n","x = LeakyReLU()(x)\n","x = Dropout(0.25)(x)\n","\n","x = Conv2D(128, 4, strides=2)(x)\n","x = BatchNormalization(momentum=0.8)(x)\n","x = LeakyReLU()(x)\n","x = Dropout(0.25)(x)\n","\n","x = Conv2D(128, 4, strides=2)(x)\n","x = BatchNormalization(momentum=0.8)(x)\n","x = LeakyReLU()(x)\n","x = Dropout(0.25)(x)\n","\n","x = Conv2D(128, 4, strides=2)(x)\n","x = LeakyReLU()(x)\n","x = Flatten()(x)\n","#x = Dense(128, activation='tanh')(x)\n","x = Dropout(0.4)(x)\n","\n","x = Dense(1, activation='sigmoid')(x)\n","descriminator = Model(descriminator_input, x)\n","descriminator.summary()\n","\n","#descriminator_optimizer = Adam(lr=0.0004,clipvalue=1.0, decay=1e-8)\n","descriminator_optimizer = Adam(lr=0.0002,clipvalue=1.0, decay=1e-8)\n","\n","descriminator.compile(optimizer=descriminator_optimizer, loss='binary_crossentropy')\n","\n","descriminator.trainable = False\n","\n","#gan\n","gan_input = Input(shape=(latent_dim, ))\n","gan_output = descriminator(generator(gan_input))\n","gan = Model(gan_input, gan_output)\n","\n","#gan_optimizer = Adam(lr=0.0004,clipvalue=1.0, decay=1e-8)\n","gan_optimizer = Adam(lr=0.0002,clipvalue=1.0, decay=1e-8)\n","gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')\n","\n","\n","#training the gan\n","(X_train, y_train), (_,_) = cifar10.load_data()\n","X_train  = X_train[y_train.flatten() == 6]\n","X_train = X_train.reshape((X_train.shape[0], )+(height, width, channels)).astype('float32')/255.\n","\n","iterations = 4000\n","batch_size = 32\n","save_dir = \"./gen1\"\n","start = 0\n","\n","for step in range(iterations):\n","    random_latent_vectors = np.random.normal(size = (batch_size, latent_dim)) #sample random points\n","    generated_images = generator.predict(random_latent_vectors) #output of the generator (decoded fake images)\n","    \n","    stop = start + batch_size\n","    real_images = X_train[start:stop]\n","    combined_images = np.concatenate([generated_images, real_images])#combine fake and real images\n","    \n","    labels = np.concatenate([np.zeros((batch_size, 1)), np.ones((batch_size, 1))])\n","    #labels += 0.005*np.random.random(size=labels.shape) #add noise to the labels\n","    \n","    d_loss = descriminator.train_on_batch(combined_images, labels) #train the descriminator\n","    \n","    random_latent_vectors = np.random.normal(size = (batch_size, latent_dim))#sample random vectors\n","    misleading_targets = np.ones((batch_size, 1)) #labels that lie that they are real images\n","    \n","    a_loss = gan.train_on_batch(random_latent_vectors, misleading_targets) #train generator model via gan\n","    \n","    start += batch_size\n","    if start > len(X_train)-batch_size:\n","        start = 0\n","    \n","    if step %100 ==0:\n","        gan.save_weights('gan.h5')\n","        \n","        print(\"discriminator loss \",step,\" : \", d_loss)\n","        print(\"adverserial loss : \",step,\" : \", a_loss)\n","        \n","        img = Image.array_to_img(generated_images[0] * 255., scale=False)\n","        img.save(\"cifar10/generated_frog_\"+str(step)+'.png')\n","\n","        "],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_76 (InputLayer)        (None, 32)                0         \n","_________________________________________________________________\n","dense_53 (Dense)             (None, 32768)             1081344   \n","_________________________________________________________________\n","leaky_re_lu_207 (LeakyReLU)  (None, 32768)             0         \n","_________________________________________________________________\n","reshape_28 (Reshape)         (None, 16, 16, 128)       0         \n","_________________________________________________________________\n","conv2d_202 (Conv2D)          (None, 16, 16, 256)       819456    \n","_________________________________________________________________\n","batch_normalization_156 (Bat (None, 16, 16, 256)       1024      \n","_________________________________________________________________\n","leaky_re_lu_208 (LeakyReLU)  (None, 16, 16, 256)       0         \n","_________________________________________________________________\n","up_sampling2d_30 (UpSampling (None, 32, 32, 256)       0         \n","_________________________________________________________________\n","leaky_re_lu_209 (LeakyReLU)  (None, 32, 32, 256)       0         \n","_________________________________________________________________\n","conv2d_203 (Conv2D)          (None, 32, 32, 256)       1638656   \n","_________________________________________________________________\n","batch_normalization_157 (Bat (None, 32, 32, 256)       1024      \n","_________________________________________________________________\n","leaky_re_lu_210 (LeakyReLU)  (None, 32, 32, 256)       0         \n","_________________________________________________________________\n","conv2d_204 (Conv2D)          (None, 32, 32, 256)       1638656   \n","_________________________________________________________________\n","batch_normalization_158 (Bat (None, 32, 32, 256)       1024      \n","_________________________________________________________________\n","leaky_re_lu_211 (LeakyReLU)  (None, 32, 32, 256)       0         \n","_________________________________________________________________\n","conv2d_205 (Conv2D)          (None, 32, 32, 3)         37635     \n","=================================================================\n","Total params: 5,218,819\n","Trainable params: 5,217,283\n","Non-trainable params: 1,536\n","_________________________________________________________________\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_77 (InputLayer)        (None, 32, 32, 3)         0         \n","_________________________________________________________________\n","conv2d_206 (Conv2D)          (None, 30, 30, 128)       3584      \n","_________________________________________________________________\n","leaky_re_lu_212 (LeakyReLU)  (None, 30, 30, 128)       0         \n","_________________________________________________________________\n","dropout_102 (Dropout)        (None, 30, 30, 128)       0         \n","_________________________________________________________________\n","conv2d_207 (Conv2D)          (None, 14, 14, 128)       262272    \n","_________________________________________________________________\n","batch_normalization_159 (Bat (None, 14, 14, 128)       512       \n","_________________________________________________________________\n","leaky_re_lu_213 (LeakyReLU)  (None, 14, 14, 128)       0         \n","_________________________________________________________________\n","dropout_103 (Dropout)        (None, 14, 14, 128)       0         \n","_________________________________________________________________\n","conv2d_208 (Conv2D)          (None, 6, 6, 128)         262272    \n","_________________________________________________________________\n","batch_normalization_160 (Bat (None, 6, 6, 128)         512       \n","_________________________________________________________________\n","leaky_re_lu_214 (LeakyReLU)  (None, 6, 6, 128)         0         \n","_________________________________________________________________\n","dropout_104 (Dropout)        (None, 6, 6, 128)         0         \n","_________________________________________________________________\n","conv2d_209 (Conv2D)          (None, 2, 2, 128)         262272    \n","_________________________________________________________________\n","leaky_re_lu_215 (LeakyReLU)  (None, 2, 2, 128)         0         \n","_________________________________________________________________\n","flatten_26 (Flatten)         (None, 512)               0         \n","_________________________________________________________________\n","dropout_105 (Dropout)        (None, 512)               0         \n","_________________________________________________________________\n","dense_54 (Dense)             (None, 1)                 513       \n","=================================================================\n","Total params: 791,937\n","Trainable params: 791,425\n","Non-trainable params: 512\n","_________________________________________________________________\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n","  'Discrepancy between trainable weights and collected trainable'\n"],"name":"stderr"},{"output_type":"stream","text":["discriminator loss  0  :  0.79147315\n","adverserial loss :  0  :  0.75722456\n","discriminator loss  100  :  7.196488e-05\n","adverserial loss :  100  :  0.012157657\n","discriminator loss  200  :  0.00011395703\n","adverserial loss :  200  :  0.00586361\n","discriminator loss  300  :  4.3258373e-05\n","adverserial loss :  300  :  0.0023058406\n","discriminator loss  400  :  2.9299707e-05\n","adverserial loss :  400  :  0.00422142\n","discriminator loss  500  :  1.7357868e-05\n","adverserial loss :  500  :  0.0017512488\n","discriminator loss  600  :  2.8087728e-05\n","adverserial loss :  600  :  0.001318652\n","discriminator loss  700  :  1.6755259e-05\n","adverserial loss :  700  :  0.00097054924\n","discriminator loss  800  :  7.988632e-06\n","adverserial loss :  800  :  0.0015461742\n"],"name":"stdout"}]},{"metadata":{"id":"hzztchUNFMjL","colab_type":"code","colab":{}},"cell_type":"code","source":["for step in range(iterations):\n","    random_latent_vectors = np.random.normal(size = (batch_size, latent_dim)) #sample random points\n","    generated_images = generator.predict(random_latent_vectors) #output of the generator (decoded fake images)\n","    \n","    stop = start + batch_size\n","    real_images = X_train[start:stop]\n","    combined_images = np.concatenate([generated_images, real_images])#combine fake and real images\n","    \n","    labels = np.concatenate([np.zeros((batch_size, 1)), np.ones((batch_size, 1))])\n","    #labels += 0.005*np.random.random(size=labels.shape) #add noise to the labels\n","    \n","    d_loss = descriminator.train_on_batch(combined_images, labels) #train the descriminator\n","    \n","    random_latent_vectors = np.random.normal(size = (batch_size, latent_dim))#sample random vectors\n","    misleading_targets = np.ones((batch_size, 1)) #labels that lie that they are real images\n","    \n","    a_loss = gan.train_on_batch(random_latent_vectors, misleading_targets) #train generator model via gan\n","    \n","    start += batch_size\n","    if start > len(X_train)-batch_size:\n","        start = 0\n","    \n","    if step %10 ==0:\n","        gan.save_weights('gan.h5')\n","        \n","        print(\"discriminator loss \",step,\" : \", d_loss)\n","        print(\"adverserial loss : \",step,\" : \", a_loss)\n","        \n","        img = Image.array_to_img(generated_images[0] * 255., scale=False)\n","        img.save(\"cifar10/generated_frog_\"+str(step)+'.png')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Mfp_ry4TCaEB","colab_type":"code","colab":{}},"cell_type":"code","source":["class DCGAN(): \n","  def __init__(self, name= \"mnist\", imgrows=32, imgcols=32, channels= 3, latent_dim= 100):\n","    self.name= name\n","    self.img_rows= imgrows\n","    self.img_cols= imgcols\n","    self.channels= channels\n","    self.img_shape= (self.img_rows, self.img_cols, self.channels)\n","    self.latent_dim= latent_dim\n","    \n","    #parameters chosen from the paper by Radford et al.\n","    optimizer= Adam(0.0002, 0.5)\n","    \n","    #construct generator\n","    self.generator= self.generator()\n","    \n","    #construct discriminator\n","    self.discriminator= self.discriminator()\n","    self.discriminator.compile(loss= \"binary_crossentropy\",\n","                              optimizer= optimizer, \n","                              metrics= ['accuracy'])\n","    \n","    #generator generates images from noise\n","    noise= Input(shape= (self.latent_dim, ))\n","    img= self.generator(noise)\n","    \n","    #only train generator\n","    self.discriminator.trainable= False\n","    \n","    #validity of image as determined by discriminator\n","    val= self.discriminator(img)\n","    \n","    #stack generator and discriminator\n","    self.GAN = Model(noise, val)\n","    self.GAN.compile(loss= \"binary_crossentropy\", optimizer= optimizer)\n","    \n","  \n","  def generator(self): \n","    model = Sequential()\n","    model.add(Dense(128 * 16 * 16, activation= \"relu\", input_dim= self.latent_dim))\n","    model.add(LeakyReLU(0.2))\n","    model.add(Reshape((16, 16, 128)))\n","    model.add(Conv2D(256, kernel_size= 5, padding= \"same\"))\n","    model.add(BatchNormalization(momentum= 0.8))\n","    model.add(LeakyReLU(0.2))\n","    model.add(UpSampling2D())\n","    model.add(Conv2D(256, kernel_size= 3, padding= \"same\"))\n","    model.add(BatchNormalization(momentum= 0.8))\n","    model.add(LeakyReLU(0.2))\n","    model.add(Conv2D(256, 5, padding= \"same\"))\n","    model.add(BatchNormalization(momentum= 0.8))\n","    model.add(LeakyReLU(0.2))\n","    model.add(Conv2D(self.channels, kernel_size= 7, activation= 'tanh', padding= \"same\"))\n","    model.add(Activation(\"tanh\"))\n","    print(\"Generator Summary ... \")\n","    model.summary()\n","    \n","    #input noise into generator\n","    noise= Input(shape= (self.latent_dim, ))\n","    #pass noise through model to retrieve image\n","    img= model(noise)\n","    \n","    return Model(noise, img)\n","  \n","  def discriminator(self): \n","    model= Sequential()\n","    model.add(Conv2D(128, kernel_size= 3, strides= 2, input_shape= self.img_shape, padding= \"same\"))\n","    model.add(LeakyReLU(alpha= 0.2))\n","    model.add(Dropout(0.25))\n","    model.add(Conv2D(128, kernel_size= 4, strides= 2, padding= \"same\"))\n","    model.add(ZeroPadding2D(padding= ((0, 1), (0, 1))))\n","    model.add(BatchNormalization(momentum= 0.8))\n","    model.add(LeakyReLU(alpha= 0.2))\n","    model.add(Dropout(0.25))\n","    model.add(Conv2D(128, kernel_size= 4, strides= 2, padding= \"same\"))\n","    model.add(BatchNormalization(momentum= 0.8))\n","    model.add(LeakyReLU(alpha= 0.2))\n","    model.add(Dropout(0.25))\n","    model.add(Conv2D(128, kernel_size=4, strides= 2, padding= \"same\"))\n","    model.add(BatchNormalization(momentum= 0.8))\n","    model.add(LeakyReLU(alpha= 0.2))\n","    model.add(Dropout(0.25))\n","    model.add(Flatten())\n","    model.add(Dense(1, activation= \"sigmoid\"))\n","    print(\"Discriminator Summary ... \")\n","    model.summary()\n","    \n","    img= Input(shape= self.img_shape)\n","    val= model(img)\n","    return Model(img, val)\n","  \n","  def images(self, noise, rows= 5, cols= 5, name= \"untitled\", title= \"\",\n","             show= False): \n","    generated= self.generator.predict(noise)\n","    \n","    #rescale images to [0, 1]\n","    generated= 0.5* generated + 0.5\n","    \n","    fig, ax= plt.subplots(rows, cols)\n","    count= 0\n","    for row in range(rows): \n","      for col in range(cols): \n","        img = Image.array_to_img(generated[count])\n","        ax[row, col].imshow(img)\n","        ax[row, col].axis(\"off\")\n","        count += 1\n","    \n","    fig.suptitle(title)    \n","    fig.savefig(\"%s.png\" % name)\n","    \n","    # Used to return the plot as an image rray\n","    fig.canvas.draw()       # draw the canvas, cache the renderer\n","    image = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n","    image = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n","    \n","    if not show: \n","      plt.close()\n","    \n","    return image\n","    \n","      \n","  def train(self, images, epochs= 8000, batch_size= 32, \n","           interval= 100, rows= 5, cols= 5):\n","    #purely for saving purposes ...\n","    fixed_noise_batch= np.random.normal(0, 1, (rows * cols, self.latent_dim))\n","    plots= []\n","    \n","    #if the directory specified by name doesn't exist, create it\n","    if not os.path.exists(self.name):\n","       os.makedirs(self.name)\n","\n","    #adversarial ground truths\n","    valid = np.ones((batch_size, 1))\n","    fake = np.zeros((batch_size, 1))\n","    \n","    start= 0\n","\n","    for epoch in range(epochs + 1):\n","      noise= np.random.normal(size= (batch_size, self.latent_dim))\n","      generated= self.generator.predict(noise)\n","      \n","      stop = start+ batch_size\n","      real= images[start: stop]\n","      combined_images= np.concatenate([generated, real])\n","      labels= np.concatenate([fake, valid])\n","      \n","      \n","      d_loss = self.discriminator.train_on_batch(combined_images, labels)\n","      g_loss = self.GAN.train_on_batch(noise, valid)\n","      \n","      start += batch_size\n","      if start > len(X_train)-batch_size:\n","        start = 0\n","        \n","      if epoch % interval == 0:\n","        status= \"[%d] D loss: %f, acc: %.2f%% || G loss: %f\" %(epoch, \n","                 d_loss[0], d_loss[1] * 100, g_loss)\n","        print(status)\n","        \n","        #generate images\n","        name= \"%s/%d\" % (self.name, epoch)\n","        plot= self.images(name= name, noise= fixed_noise_batch, \n","                          title= status, rows= rows, cols= cols)\n","        plots.append(plot)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5hCX0HLvS6mP","colab_type":"text"},"cell_type":"markdown","source":["## Run the Code\n","Below is the code to run the dcgan on the mnist dataset. "]},{"metadata":{"id":"arwTiZxTxYyN","colab_type":"code","outputId":"8a65fbae-dd2e-4168-b20f-ce6132bb3b63","executionInfo":{"status":"ok","timestamp":1547439461226,"user_tz":480,"elapsed":4580,"user":{"displayName":"Hao Chuan Lei","photoUrl":"","userId":"04091475403023878525"}},"colab":{"base_uri":"https://localhost:8080/","height":1411}},"cell_type":"code","source":["(X_train, _), (_, _) = cifar10.load_data()\n","dcgan= DCGAN(name= \"cifar10\", imgrows= 32, imgcols= 32, channels= 3)"],"execution_count":64,"outputs":[{"output_type":"stream","text":["Generator Summary ... \n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_51 (Dense)             (None, 32768)             3309568   \n","_________________________________________________________________\n","leaky_re_lu_199 (LeakyReLU)  (None, 32768)             0         \n","_________________________________________________________________\n","reshape_27 (Reshape)         (None, 16, 16, 128)       0         \n","_________________________________________________________________\n","conv2d_194 (Conv2D)          (None, 16, 16, 256)       819456    \n","_________________________________________________________________\n","batch_normalization_150 (Bat (None, 16, 16, 256)       1024      \n","_________________________________________________________________\n","leaky_re_lu_200 (LeakyReLU)  (None, 16, 16, 256)       0         \n","_________________________________________________________________\n","up_sampling2d_29 (UpSampling (None, 32, 32, 256)       0         \n","_________________________________________________________________\n","conv2d_195 (Conv2D)          (None, 32, 32, 256)       590080    \n","_________________________________________________________________\n","batch_normalization_151 (Bat (None, 32, 32, 256)       1024      \n","_________________________________________________________________\n","leaky_re_lu_201 (LeakyReLU)  (None, 32, 32, 256)       0         \n","_________________________________________________________________\n","conv2d_196 (Conv2D)          (None, 32, 32, 256)       1638656   \n","_________________________________________________________________\n","batch_normalization_152 (Bat (None, 32, 32, 256)       1024      \n","_________________________________________________________________\n","leaky_re_lu_202 (LeakyReLU)  (None, 32, 32, 256)       0         \n","_________________________________________________________________\n","conv2d_197 (Conv2D)          (None, 32, 32, 3)         37635     \n","_________________________________________________________________\n","activation_19 (Activation)   (None, 32, 32, 3)         0         \n","=================================================================\n","Total params: 6,398,467\n","Trainable params: 6,396,931\n","Non-trainable params: 1,536\n","_________________________________________________________________\n","Discriminator Summary ... \n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_198 (Conv2D)          (None, 16, 16, 128)       3584      \n","_________________________________________________________________\n","leaky_re_lu_203 (LeakyReLU)  (None, 16, 16, 128)       0         \n","_________________________________________________________________\n","dropout_98 (Dropout)         (None, 16, 16, 128)       0         \n","_________________________________________________________________\n","conv2d_199 (Conv2D)          (None, 8, 8, 128)         262272    \n","_________________________________________________________________\n","zero_padding2d_19 (ZeroPaddi (None, 9, 9, 128)         0         \n","_________________________________________________________________\n","batch_normalization_153 (Bat (None, 9, 9, 128)         512       \n","_________________________________________________________________\n","leaky_re_lu_204 (LeakyReLU)  (None, 9, 9, 128)         0         \n","_________________________________________________________________\n","dropout_99 (Dropout)         (None, 9, 9, 128)         0         \n","_________________________________________________________________\n","conv2d_200 (Conv2D)          (None, 5, 5, 128)         262272    \n","_________________________________________________________________\n","batch_normalization_154 (Bat (None, 5, 5, 128)         512       \n","_________________________________________________________________\n","leaky_re_lu_205 (LeakyReLU)  (None, 5, 5, 128)         0         \n","_________________________________________________________________\n","dropout_100 (Dropout)        (None, 5, 5, 128)         0         \n","_________________________________________________________________\n","conv2d_201 (Conv2D)          (None, 3, 3, 128)         262272    \n","_________________________________________________________________\n","batch_normalization_155 (Bat (None, 3, 3, 128)         512       \n","_________________________________________________________________\n","leaky_re_lu_206 (LeakyReLU)  (None, 3, 3, 128)         0         \n","_________________________________________________________________\n","dropout_101 (Dropout)        (None, 3, 3, 128)         0         \n","_________________________________________________________________\n","flatten_25 (Flatten)         (None, 1152)              0         \n","_________________________________________________________________\n","dense_52 (Dense)             (None, 1)                 1153      \n","=================================================================\n","Total params: 793,089\n","Trainable params: 792,321\n","Non-trainable params: 768\n","_________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"-GfCaBgm9UUf","colab_type":"code","outputId":"3566a34b-429d-40ab-b333-5926a54989aa","executionInfo":{"status":"error","timestamp":1547439635770,"user_tz":480,"elapsed":169662,"user":{"displayName":"Hao Chuan Lei","photoUrl":"","userId":"04091475403023878525"}},"colab":{"base_uri":"https://localhost:8080/","height":915}},"cell_type":"code","source":["dcgan.train(images= X_train)"],"execution_count":65,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n","  'Discrepancy between trainable weights and collected trainable'\n"],"name":"stderr"},{"output_type":"stream","text":["[0] D loss: 0.533711, acc: 62.50% || G loss: 0.421324\n","[100] D loss: 0.000161, acc: 100.00% || G loss: 0.000290\n","[200] D loss: 0.000089, acc: 100.00% || G loss: 0.000044\n","[300] D loss: 0.000204, acc: 100.00% || G loss: 0.000026\n","[400] D loss: 0.000024, acc: 100.00% || G loss: 0.000024\n","[500] D loss: 0.000010, acc: 100.00% || G loss: 0.000017\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-65-9c7d7b0b90a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdcgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-63-c2418d93208d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, images, epochs, batch_size, interval, rows, cols)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m       \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m       \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGAN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m       \u001b[0mstart\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}